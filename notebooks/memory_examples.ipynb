{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chats and memory with langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the OPEN AI KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load openai key\n",
    "with open('../openaikey.txt', \"r\") as file:\n",
    "    # Read the contents of the file\n",
    "    OPENAI_KEY = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(openai_api_key=OPENAI_KEY, model_name='gpt-3.5-turbo', temperature=0, max_tokens=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries for chat schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = [\n",
    "    SystemMessage(content='Hello, I am a chatbot. I am here to help you with your questions.'),\n",
    "    HumanMessage(content='Hello, I have a question about my order.'),\n",
    "    AIMessage(content='Yes, go ahead and tell me your question.'),\n",
    "    HumanMessage(content='How much is 2 + 2?'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = llm(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The sum of 2 + 2 is 4.', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue with the chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "message.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a new question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "message.append(HumanMessage(content='Ok, thanks!, now tell me what is the difference between Canada and USA'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = llm(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Canada and the United States are neighboring countries in North America, but there are several differences between them. Here are a few key distinctions:\\n\\n1. Government and Political Systems: Canada is a parliamentary democracy with a constitutional monarchy, where the British monarch is the head of state. The United States, on the other hand, is a federal republic with a presidential system.\\n\\n2. Healthcare: Canada has a publicly funded healthcare system known as Medicare, which provides universal healthcare coverage to all Canadian citizens and permanent residents. In the United States, healthcare is primarily provided through private insurance, and access to healthcare can vary depending on individual insurance coverage.\\n\\n3. Education: Both countries have strong education systems, but there are some differences. In Canada, education is primarily a provincial responsibility, resulting in some variations across provinces. In the United States, education is primarily a state and local responsibility, leading to differences in curriculum and funding between states.\\n\\n4. Cultural Diversity: Both Canada and the United States are diverse countries, but they have different demographic compositions. Canada has a higher percentage of immigrants and is known for its multiculturalism policy, which promotes the preservation and celebration of diverse cultures. The United States has a larger population and is often referred to as a \"melting pot\"', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat templates\n",
    "\n",
    "They´re useful when it is needed to add information in a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_system = \"\"\"\n",
    "You are an expert to answer questions about {brand}.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_system = SystemMessagePromptTemplate.from_template(template_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_human = \"\"\" \n",
    "{question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "promt_human = HumanMessagePromptTemplate.from_template(template_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_chat = ChatPromptTemplate.from_messages([template_system, template_human])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_chat_format = prompt_chat.format_prompt(brand = 'Apple', question = 'How much does it cost the newest phone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI language model, I don't have real-time information on the latest Apple products and their prices. However, as of my last update, the newest iPhone models released by Apple are typically priced starting from around $699 for the base model. However, prices can vary depending on the specific model, storage capacity, and any additional features or accessories. It's always best to check Apple's official website or authorized retailers for the most accurate and up-to-date pricing information.\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(prompt_chat_format.to_messages())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.memory import ConversationBufferMemory \n",
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ConversationBufferMemory is suitable in scenarios where the conversation is going to be less than 6 interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(memory=memory, llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Quien descrubrio America?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Cristóbal Colón descubrió América en 1492.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Quien descrubrio America?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Quien descrubrio America?\n",
      "AI: Cristóbal Colón descubrió América en 1492. Fue un navegante y explorador genovés que realizó cuatro viajes transatlánticos en nombre de los Reyes Católicos de España. En su primer viaje, llegó a las islas del Caribe y posteriormente exploró las costas de América Central y del Sur. Su descubrimiento marcó el comienzo de la colonización europea en el continente americano.\n",
      "Human: Quien fundo la empresa Platzi?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'La empresa Platzi fue fundada por Freddy Vega y Christian Van Der Henst en 2013. Platzi es una plataforma de educación en línea que ofrece cursos sobre programación, diseño, marketing y emprendimiento. La empresa tiene su sede en Bogotá, Colombia, y ha crecido rápidamente desde su fundación, convirtiéndose en una de las principales plataformas de educación en línea en América Latina.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Quien fundo la empresa Platzi?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Quien descrubrio America?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='Cristóbal Colón descubrió América en 1492. Fue un navegante y explorador genovés que realizó cuatro viajes transatlánticos en nombre de los Reyes Católicos de España. En su primer viaje, llegó a las islas del Caribe y posteriormente exploró las costas de América Central y del Sur. Su descubrimiento marcó el comienzo de la colonización europea en el continente americano.', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='Quien fundo la empresa Platzi?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='La empresa Platzi fue fundada por Freddy Vega y Christian Van Der Henst en 2013. Platzi es una plataforma de educación en línea que ofrece cursos sobre programación, diseño, marketing y emprendimiento. La empresa tiene su sede en Bogotá, Colombia, y ha crecido rápidamente desde su fundación, convirtiéndose en una de las principales plataformas de educación en línea en América Latina.', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Conversation window buffer memory\n",
    "\n",
    "This type of memory is suitable when you want to remember something specifically from the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_memory = ConversationBufferWindowMemory(k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(memory=window_memory, llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hola quien fue Jose Maria Sarasti en Ecuador\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'¡Hola! José María Sarasti fue un destacado político ecuatoriano. Nació el 19 de marzo de 1899 en Guayaquil, Ecuador, y falleció el 6 de julio de 1976 en la misma ciudad. Sarasti fue un miembro prominente del Partido Conservador y ocupó varios cargos políticos a lo largo de su carrera. Fue elegido como diputado en varias ocasiones y también se desempeñó como Ministro de Gobierno y Ministro de Relaciones Exteriores en diferentes períodos. Además, Sarasti fue conocido por su participación en la redacción de la Constitución de 1945 en Ecuador. ¿Hay algo más en lo que pueda ayudarte?'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Hola quien fue Jose Maria Sarasti en Ecuador')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hola quien fue Jose Maria Sarasti en Ecuador\n",
      "AI: ¡Hola! José María Sarasti fue un destacado político ecuatoriano. Nació el 19 de marzo de 1899 en Guayaquil, Ecuador, y falleció el 6 de julio de 1976 en la misma ciudad. Sarasti fue un miembro prominente del Partido Conservador y ocupó varios cargos políticos a lo largo de su carrera. Fue elegido como diputado en varias ocasiones y también se desempeñó como Ministro de Gobierno y Ministro de Relaciones Exteriores en diferentes períodos. Además, Sarasti fue conocido por su participación en la redacción de la Constitución de 1945 en Ecuador. ¿Hay algo más en lo que pueda ayudarte?\n",
      "Human: Cual fue la relacion de Jose Maria Sarasti con Eloy Alfaro\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'José María Sarasti y Eloy Alfaro tuvieron una relación política compleja. Ambos fueron prominentes figuras en la historia política de Ecuador, pero tuvieron diferencias ideológicas y disputas personales. Sarasti era miembro del Partido Conservador, mientras que Alfaro lideraba el Partido Liberal Radical. A pesar de sus diferencias, Sarasti y Alfaro colaboraron en algunos momentos. Por ejemplo, Sarasti fue Ministro de Gobierno durante el gobierno de Alfaro en 1906. Sin embargo, también hubo momentos de conflicto entre ellos, especialmente durante la Revolución Liberal de 1911, cuando Sarasti se opuso a Alfaro y apoyó a los conservadores. En resumen, su relación fue compleja y estuvo marcada por la política y las diferencias ideológicas. ¿Hay algo más en lo que pueda ayudarte?'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Cual fue la relacion de Jose Maria Sarasti con Eloy Alfaro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hola quien fue Jose Maria Sarasti en Ecuador\n",
      "AI: ¡Hola! José María Sarasti fue un destacado político ecuatoriano. Nació el 19 de marzo de 1899 en Guayaquil, Ecuador, y falleció el 6 de julio de 1976 en la misma ciudad. Sarasti fue un miembro prominente del Partido Conservador y ocupó varios cargos políticos a lo largo de su carrera. Fue elegido como diputado en varias ocasiones y también se desempeñó como Ministro de Gobierno y Ministro de Relaciones Exteriores en diferentes períodos. Además, Sarasti fue conocido por su participación en la redacción de la Constitución de 1945 en Ecuador. ¿Hay algo más en lo que pueda ayudarte?\n",
      "Human: Cual fue la relacion de Jose Maria Sarasti con Eloy Alfaro\n",
      "AI: José María Sarasti y Eloy Alfaro tuvieron una relación política compleja. Ambos fueron prominentes figuras en la historia política de Ecuador, pero tuvieron diferencias ideológicas y disputas personales. Sarasti era miembro del Partido Conservador, mientras que Alfaro lideraba el Partido Liberal Radical. A pesar de sus diferencias, Sarasti y Alfaro colaboraron en algunos momentos. Por ejemplo, Sarasti fue Ministro de Gobierno durante el gobierno de Alfaro en 1906. Sin embargo, también hubo momentos de conflicto entre ellos, especialmente durante la Revolución Liberal de 1911, cuando Sarasti se opuso a Alfaro y apoyó a los conservadores. En resumen, su relación fue compleja y estuvo marcada por la política y las diferencias ideológicas. ¿Hay algo más en lo que pueda ayudarte?\n",
      "Human: Calificas como positiva o negativa la gestion de Jose Maria Sarasti en Ecuador\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Como inteligencia artificial, no tengo la capacidad de emitir juicios de valor sobre la gestión de una persona. La evaluación de la gestión de José María Sarasti en Ecuador es subjetiva y depende de diferentes perspectivas y opiniones. Algunos podrían considerar su gestión como positiva debido a sus logros políticos y su participación en la redacción de la Constitución de 1945. Sin embargo, otros podrían tener una opinión negativa debido a diferencias ideológicas o a eventos específicos durante su carrera política. En última instancia, la evaluación de su gestión es una cuestión de opinión personal. ¿Hay algo más en lo que pueda ayudarte?'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Calificas como positiva o negativa la gestion de Jose Maria Sarasti en Ecuador')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Cual fue la relacion de Jose Maria Sarasti con Eloy Alfaro\n",
      "AI: José María Sarasti y Eloy Alfaro tuvieron una relación política compleja. Ambos fueron prominentes figuras en la historia política de Ecuador, pero tuvieron diferencias ideológicas y disputas personales. Sarasti era miembro del Partido Conservador, mientras que Alfaro lideraba el Partido Liberal Radical. A pesar de sus diferencias, Sarasti y Alfaro colaboraron en algunos momentos. Por ejemplo, Sarasti fue Ministro de Gobierno durante el gobierno de Alfaro en 1906. Sin embargo, también hubo momentos de conflicto entre ellos, especialmente durante la Revolución Liberal de 1911, cuando Sarasti se opuso a Alfaro y apoyó a los conservadores. En resumen, su relación fue compleja y estuvo marcada por la política y las diferencias ideológicas. ¿Hay algo más en lo que pueda ayudarte?\n",
      "Human: Calificas como positiva o negativa la gestion de Jose Maria Sarasti en Ecuador\n",
      "AI: Como inteligencia artificial, no tengo la capacidad de emitir juicios de valor sobre la gestión de una persona. La evaluación de la gestión de José María Sarasti en Ecuador es subjetiva y depende de diferentes perspectivas y opiniones. Algunos podrían considerar su gestión como positiva debido a sus logros políticos y su participación en la redacción de la Constitución de 1945. Sin embargo, otros podrían tener una opinión negativa debido a diferencias ideológicas o a eventos específicos durante su carrera política. En última instancia, la evaluación de su gestión es una cuestión de opinión personal. ¿Hay algo más en lo que pueda ayudarte?\n",
      "Human: Podrias decirme si Jose Maria Sarasti vivio en algun punto en Pujili Cotopaxi\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No tengo información específica sobre si José María Sarasti vivió en algún momento en Pujilí, Cotopaxi. Mi conocimiento se basa en datos generales y no tengo acceso a información detallada sobre la vida personal de individuos específicos. Sería recomendable buscar fuentes más especializadas o consultar con expertos en la historia de Ecuador para obtener información más precisa sobre la residencia de José María Sarasti. ¿Hay algo más en lo que pueda ayudarte?'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Podrias decirme si Jose Maria Sarasti vivio en algun punto en Pujili Cotopaxi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Calificas como positiva o negativa la gestion de Jose Maria Sarasti en Ecuador\n",
      "AI: Como inteligencia artificial, no tengo la capacidad de emitir juicios de valor sobre la gestión de una persona. La evaluación de la gestión de José María Sarasti en Ecuador es subjetiva y depende de diferentes perspectivas y opiniones. Algunos podrían considerar su gestión como positiva debido a sus logros políticos y su participación en la redacción de la Constitución de 1945. Sin embargo, otros podrían tener una opinión negativa debido a diferencias ideológicas o a eventos específicos durante su carrera política. En última instancia, la evaluación de su gestión es una cuestión de opinión personal. ¿Hay algo más en lo que pueda ayudarte?\n",
      "Human: Podrias decirme si Jose Maria Sarasti vivio en algun punto en Pujili Cotopaxi\n",
      "AI: No tengo información específica sobre si José María Sarasti vivió en algún momento en Pujilí, Cotopaxi. Mi conocimiento se basa en datos generales y no tengo acceso a información detallada sobre la vida personal de individuos específicos. Sería recomendable buscar fuentes más especializadas o consultar con expertos en la historia de Ecuador para obtener información más precisa sobre la residencia de José María Sarasti. ¿Hay algo más en lo que pueda ayudarte?\n",
      "Human: Como es el clima en Ecuador\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ecuador tiene una gran diversidad climática debido a su ubicación geográfica y su topografía variada. En general, el clima en Ecuador se puede dividir en cuatro regiones principales: la costa, la sierra, la región amazónica y las Islas Galápagos.\\n\\nEn la costa, el clima es tropical y húmedo, con temperaturas promedio que oscilan entre los 25°C y 31°C. La temporada de lluvias va de diciembre a mayo, mientras que la temporada seca va de junio a noviembre.\\n\\nEn la sierra, el clima varía según la altitud. En las tierras altas, como Quito, el clima es templado y primaveral durante todo el año, con temperaturas promedio que oscilan entre los 15°C y 25°C. Sin embargo, en las zonas más altas de la sierra, como los páramos, las temperaturas pueden descender por debajo de los 0°C.\\n\\nEn la región amazónica, el clima es tropical y húmedo durante todo el año, con temperaturas promedio que osc'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Como es el clima en Ecuador')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Podrias decirme si Jose Maria Sarasti vivio en algun punto en Pujili Cotopaxi\n",
      "AI: No tengo información específica sobre si José María Sarasti vivió en algún momento en Pujilí, Cotopaxi. Mi conocimiento se basa en datos generales y no tengo acceso a información detallada sobre la vida personal de individuos específicos. Sería recomendable buscar fuentes más especializadas o consultar con expertos en la historia de Ecuador para obtener información más precisa sobre la residencia de José María Sarasti. ¿Hay algo más en lo que pueda ayudarte?\n",
      "Human: Como es el clima en Ecuador\n",
      "AI: Ecuador tiene una gran diversidad climática debido a su ubicación geográfica y su topografía variada. En general, el clima en Ecuador se puede dividir en cuatro regiones principales: la costa, la sierra, la región amazónica y las Islas Galápagos.\n",
      "\n",
      "En la costa, el clima es tropical y húmedo, con temperaturas promedio que oscilan entre los 25°C y 31°C. La temporada de lluvias va de diciembre a mayo, mientras que la temporada seca va de junio a noviembre.\n",
      "\n",
      "En la sierra, el clima varía según la altitud. En las tierras altas, como Quito, el clima es templado y primaveral durante todo el año, con temperaturas promedio que oscilan entre los 15°C y 25°C. Sin embargo, en las zonas más altas de la sierra, como los páramos, las temperaturas pueden descender por debajo de los 0°C.\n",
      "\n",
      "En la región amazónica, el clima es tropical y húmedo durante todo el año, con temperaturas promedio que osc\n",
      "Human: Dime algo de Pujili\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Pujilí es una ciudad ubicada en la provincia de Cotopaxi, en Ecuador. Se encuentra a una altitud de aproximadamente 2,800 metros sobre el nivel del mar. Pujilí es conocida por su rica cultura indígena y su tradición agrícola.\\n\\nLa ciudad cuenta con varios atractivos turísticos, como la Iglesia Matriz de Pujilí, que es un importante sitio histórico y arquitectónico. También puedes visitar el Mercado de Pujilí, donde encontrarás una gran variedad de productos locales, como frutas, verduras y artesanías.\\n\\nAdemás, Pujilí es famosa por sus festividades tradicionales, como la Fiesta de la Mama Negra, que se celebra en septiembre. Durante esta festividad, se realizan desfiles coloridos y se llevan a cabo representaciones teatrales que muestran la mezcla de las culturas indígena y española.\\n\\nEn cuanto a la economía, Pujilí se basa principalmente en la agricultura y la ganadería. Los principales cultivos incluyen maíz'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Dime algo de Pujili')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Conversation Summary Memory\n",
    "\n",
    "This tools avoids to save all data, in this case, it is only saved a summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LP00035\\anaconda3\\envs\\openai\\lib\\site-packages\\langchain\\__init__.py:24: UserWarning: Importing OpenAI from langchain root module is no longer supported.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.conversation.memory import ConversationSummaryMemory\n",
    "from langchain import OpenAI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it must be used a LLM for the summary\n",
    "summary_memory = ConversationSummaryMemory(llm=OpenAI(openai_api_key=OPENAI_KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation =  ConversationChain(memory=summary_memory, llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi which football team is the most popular in Spain?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hi! The most popular football team in Spain is Real Madrid. They have a huge fan base and have won numerous domestic and international titles.'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Hi which football team is the most popular in Spain?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential. The AI also states that the most popular football team in Spain is Real Madrid, with a huge fan base and many domestic and international titles.\n",
      "Human: Why not Barcelona is not the most popular team in Spain?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Barcelona is indeed a very popular football team in Spain, but Real Madrid has historically had a larger fan base and has won more domestic and international titles. Real Madrid has a rich history and has consistently been one of the most successful teams in Spanish football. However, it's important to note that popularity can vary depending on personal preferences and regional loyalties.\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Why not Barcelona is not the most popular team in Spain?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential. The AI also states that the most popular football team in Spain is Real Madrid, with a huge fan base and many domestic and international titles. The AI explains that Barcelona is also a very popular team, but Real Madrid has historically had a larger fan base and has won more titles. It is noted that popularity can vary depending on personal preferences and regional loyalties.\n",
      "Human: Is Mallorca a team from Las Palmas?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No, Mallorca is not a team from Las Palmas. Mallorca is a football team from the island of Mallorca, which is part of the Balearic Islands in Spain. Las Palmas, on the other hand, is a football team from the city of Las Palmas de Gran Canaria, which is located in the Canary Islands. Both teams compete in the Spanish football league system, but they are from different regions.'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Is Mallorca a team from Las Palmas?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      " \n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential. The AI also states that the most popular football team in Spain is Real Madrid, with a huge fan base and many domestic and international titles. It is noted that popularity can vary depending on personal preferences and regional loyalties. The human then asks if Mallorca is a team from Las Palmas, to which the AI responds that Mallorca is a team from the island of Mallorca in the Balearic Islands, while Las Palmas is a team from the city of Las Palmas de Gran Canaria in the Canary Islands.\n",
      "Human: Is Celta de Vigo from la Rioja?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No, Celta de Vigo is not from La Rioja. Celta de Vigo is a football team from the city of Vigo, which is located in the region of Galicia in northwest Spain. La Rioja, on the other hand, is an autonomous community located in northern Spain.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Is Celta de Vigo from la Rioja?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Conversation Summary Buffer Memory\n",
    "\n",
    "This kind of memory is suitable when you have small conversations, in this case, you have the option to limit the range of the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationSummaryBufferMemory(llm=OpenAI(openai_api_key=OPENAI_KEY), max_token_limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: What is a llama\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A llama is a domesticated South American camelid that is commonly used as a pack animal and for its wool. It is native to the Andes Mountains and is closely related to the alpaca. Llamas have a long neck, a slender body, and a camel-like face. They are known for their soft and warm wool, which is highly valued for its quality. Llamas are also known for their gentle and friendly nature, making them popular as pets and therapy animals. They are herbivores and primarily feed on grass and other vegetation. Llamas are social animals and live in herds, typically led by a dominant male called a \"stud.\" They have been domesticated for thousands of years and have been used by humans for transportation, wool production, and even as guard animals for livestock.'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = 'What is a llama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: \n",
      "The human asked what a llama is and the AI responded that it is a domesticated South American camelid that is commonly used as a pack animal and for its wool. It is native to the Andes Mountains and is closely related to the alpaca. Llamas have a long neck, a slender body, and a camel-like face. They are known for their soft and warm wool, which is highly valued for its quality, and for their gentle and friendly nature, making them popular as pets and therapy animals. They are herbivores and primarily feed on grass and other vegetation, and live in herds led by a dominant male. They have been domesticated for thousands of years and have been used by humans for transportation, wool production, and even as guard animals for livestock.\n",
      "Human: Do they live in the coastal regions?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No, llamas are primarily found in the Andes Mountains of South America, which are not coastal regions. They are adapted to the high altitudes and cold climates of the mountainous regions. However, llamas have been introduced to other parts of the world, including coastal regions, where they can adapt to different climates and environments.'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = 'Do they live in the coastal regions?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: \n",
      "The human asked what a llama is and the AI responded that it is a domesticated South American camelid that is commonly used as a pack animal and for its wool. It is native to the Andes Mountains and is closely related to the alpaca. Llamas have a long neck, a slender body, and a camel-like face, are herbivores, and are known for their soft and warm wool, gentle and friendly nature, making them popular as pets and therapy animals. They have been domesticated for thousands of years and have been used by humans for transportation, wool production, and even as guard animals for livestock. The AI then clarified that llamas are primarily found in the Andes Mountains of South America and are adapted to the high altitudes and cold climates of the mountainous regions, but they can also adapt to different climates and environments in other parts of the world, including coastal regions.\n",
      "Human: What are differences between llama an vicuña?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Llamas and vicuñas are both South American camelids, but there are several differences between them. Firstly, their physical appearance is distinct. Llamas are larger and have a more robust build compared to vicuñas, which are smaller and more delicate. Llamas have a long neck, a slender body, and a camel-like face, while vicuñas have a shorter neck, a compact body, and a more deer-like face.\\n\\nAnother difference is their natural habitat. Llamas are primarily found in the Andes Mountains of South America, whereas vicuñas inhabit the high-altitude regions of the Andes, particularly in Peru, Bolivia, Chile, and Argentina. Vicuñas are specifically adapted to live in the harsh conditions of the high mountains, where temperatures can be extremely cold and oxygen levels are lower.\\n\\nTheir wool is also different. Llamas have a thicker and coarser wool, which is commonly used for making clothing, blankets, and other textiles. On the other hand, vicuñas produce one of the finest and most expensive wools in the world. Vicuña wool is incredibly soft, lightweight, and warm, making it highly sought after for luxury garments.\\n\\nIn terms of behavior, ll'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = 'What are differences between llama an vicuña?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: \n",
      "The human asked what a llama is and the AI responded that it is a domesticated South American camelid that is commonly used as a pack animal and for its wool. It is native to the Andes Mountains and is closely related to the alpaca. Llamas have a long neck, a slender body, and a camel-like face, are herbivores, and are known for their soft and warm wool, gentle and friendly nature, making them popular as pets and therapy animals. They have been domesticated for thousands of years and have been used by humans for transportation, wool production, and even as guard animals for livestock. The AI then clarified that llamas are primarily found in the Andes Mountains of South America and are adapted to the high altitudes and cold climates of the mountainous regions, but they can also adapt to different climates and environments in other parts of the world, including coastal regions. The AI then went on to explain the differences between llamas and vicuñas, including their physical appearance, natural habitat, wool, and behavior. \n",
      "\n",
      "Human: Is a guanaco the same as a llama?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No, a guanaco is not the same as a llama. While both are South American camelids, they are different species. Guanacos are wild animals and are found in the wild in the Andes Mountains of South America, whereas llamas are domesticated and can be found in various parts of the world. Guanacos are smaller than llamas and have a slender body, long legs, and a short tail. They have a similar camel-like face to llamas but lack the distinctive hump on their back. Guanacos have a different natural habitat and behavior compared to llamas. They are adapted to live in the high altitudes and cold climates of the Andes Mountains, and they are known for their agility and ability to navigate rocky terrains. Guanacos have a different type of wool compared to llamas, which is coarser and less desirable for commercial use.'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = 'Is a guanaco the same as a llama?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ConversationSummaryBufferMemory' object has no attribute 'template'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\LP00035\\Documents\\CURSOS\\Lang chain\\notebooks\\memory_examples.ipynb Cell 63\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/LP00035/Documents/CURSOS/Lang%20chain/notebooks/memory_examples.ipynb#Y216sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m conversation\u001b[39m.\u001b[39;49mmemory\u001b[39m.\u001b[39;49mtemplate\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ConversationSummaryBufferMemory' object has no attribute 'template'"
     ]
    }
   ],
   "source": [
    "conversation.memory.template "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Memory Entity\n",
    "\n",
    "This memory helps to save information given from users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
